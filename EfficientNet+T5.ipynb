{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "name": "EfficientNet+T5.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "toc_visible": true,
      "machine_shape": "hm"
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "89f2469c883d4242a182854ce47f2ed8": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "state": {
            "_view_name": "HBoxView",
            "_dom_classes": [],
            "_model_name": "HBoxModel",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "box_style": "",
            "layout": "IPY_MODEL_9ef92ef3c95144f99544bf7bb3ee3012",
            "_model_module": "@jupyter-widgets/controls",
            "children": [
              "IPY_MODEL_9318e4693359435cbc1abb3d866f24db",
              "IPY_MODEL_fc15df7b82c641699c8093dc5018ff23"
            ]
          }
        },
        "9ef92ef3c95144f99544bf7bb3ee3012": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": "row wrap",
            "width": "100%",
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": "inline-flex",
            "left": null
          }
        },
        "9318e4693359435cbc1abb3d866f24db": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "state": {
            "_view_name": "ProgressView",
            "style": "IPY_MODEL_8f0f96ae44384b72a5a25491eebd964b",
            "_dom_classes": [],
            "description": "Validation sanity check:   0%",
            "_model_name": "FloatProgressModel",
            "bar_style": "danger",
            "max": 1,
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": 0,
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "orientation": "horizontal",
            "min": 0,
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_bdcacd64868d42dab819d647920ffab4"
          }
        },
        "fc15df7b82c641699c8093dc5018ff23": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "state": {
            "_view_name": "HTMLView",
            "style": "IPY_MODEL_27c74922fe4741bfb149a2670e39c235",
            "_dom_classes": [],
            "description": "",
            "_model_name": "HTMLModel",
            "placeholder": "​",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": " 0/2 [00:01&lt;?, ?it/s]",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_860f7a264f5842cca7ef013306c1b871"
          }
        },
        "8f0f96ae44384b72a5a25491eebd964b": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "ProgressStyleModel",
            "description_width": "initial",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "bar_color": null,
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "bdcacd64868d42dab819d647920ffab4": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": "2",
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "27c74922fe4741bfb149a2670e39c235": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "DescriptionStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "860f7a264f5842cca7ef013306c1b871": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "8cce9fa727dd40fba02af280b0b99c91": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "state": {
            "_view_name": "HBoxView",
            "_dom_classes": [],
            "_model_name": "HBoxModel",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "box_style": "",
            "layout": "IPY_MODEL_1f565e0840c649c5b4503321ac3aafd5",
            "_model_module": "@jupyter-widgets/controls",
            "children": [
              "IPY_MODEL_f9a5060a30ef40d08b1b097e361634a1",
              "IPY_MODEL_5017f8ce3c724db79fc0d48738cf3362"
            ]
          }
        },
        "1f565e0840c649c5b4503321ac3aafd5": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": "row wrap",
            "width": "100%",
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": "inline-flex",
            "left": null
          }
        },
        "f9a5060a30ef40d08b1b097e361634a1": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "state": {
            "_view_name": "ProgressView",
            "style": "IPY_MODEL_6a58e4f231e547a4aad7d03c3e48caa2",
            "_dom_classes": [],
            "description": "Epoch 14:   0%",
            "_model_name": "FloatProgressModel",
            "bar_style": "info",
            "max": 40531,
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": 0,
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "orientation": "horizontal",
            "min": 0,
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_c48a904f241c47bbae2d658625c404eb"
          }
        },
        "5017f8ce3c724db79fc0d48738cf3362": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "state": {
            "_view_name": "HTMLView",
            "style": "IPY_MODEL_6deba002370242e49696ea4629ac2683",
            "_dom_classes": [],
            "description": "",
            "_model_name": "HTMLModel",
            "placeholder": "​",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": " 0/40531 [00:00&lt;?, ?it/s]",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_c5bf72c2d4a84b8aa4e8ec199d3dd918"
          }
        },
        "6a58e4f231e547a4aad7d03c3e48caa2": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "ProgressStyleModel",
            "description_width": "initial",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "bar_color": null,
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "c48a904f241c47bbae2d658625c404eb": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": "2",
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "6deba002370242e49696ea4629ac2683": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "DescriptionStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "c5bf72c2d4a84b8aa4e8ec199d3dd918": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "d552ded803484eb882e57b75397aa54c": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "state": {
            "_view_name": "HBoxView",
            "_dom_classes": [],
            "_model_name": "HBoxModel",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "box_style": "",
            "layout": "IPY_MODEL_515c4545b0fb44708e36ef7894a75bbc",
            "_model_module": "@jupyter-widgets/controls",
            "children": [
              "IPY_MODEL_3cd0271d4f814fa5b0486a24dd0b220a",
              "IPY_MODEL_19b0058cf73a421a898d1b5949e64ede"
            ]
          }
        },
        "515c4545b0fb44708e36ef7894a75bbc": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": "row wrap",
            "width": "100%",
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": "inline-flex",
            "left": null
          }
        },
        "3cd0271d4f814fa5b0486a24dd0b220a": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "state": {
            "_view_name": "ProgressView",
            "style": "IPY_MODEL_abc87c7fc2114b30839c0aa894673085",
            "_dom_classes": [],
            "description": "Testing: 100%",
            "_model_name": "FloatProgressModel",
            "bar_style": "success",
            "max": 1,
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": 1,
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "orientation": "horizontal",
            "min": 0,
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_1c4eb617671445fc9a53ece103f01ef5"
          }
        },
        "19b0058cf73a421a898d1b5949e64ede": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "state": {
            "_view_name": "HTMLView",
            "style": "IPY_MODEL_21a472c1f31641ae9a5174433c33310f",
            "_dom_classes": [],
            "description": "",
            "_model_name": "HTMLModel",
            "placeholder": "​",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": " 5349/5349 [32:42&lt;00:00,  2.73it/s]",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_67378c2347fb4ab7a7aa9bde620be622"
          }
        },
        "abc87c7fc2114b30839c0aa894673085": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "ProgressStyleModel",
            "description_width": "initial",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "bar_color": null,
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "1c4eb617671445fc9a53ece103f01ef5": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": "2",
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "21a472c1f31641ae9a5174433c33310f": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "DescriptionStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "67378c2347fb4ab7a7aa9bde620be622": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "81c98735a18d4b8588b3678f196077e4": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "state": {
            "_view_name": "HBoxView",
            "_dom_classes": [],
            "_model_name": "HBoxModel",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "box_style": "",
            "layout": "IPY_MODEL_ecaa63e35d1c44ce97df09049952b0dd",
            "_model_module": "@jupyter-widgets/controls",
            "children": [
              "IPY_MODEL_8ee716506d2a4a04a9ee5b4068eed047",
              "IPY_MODEL_9773085f1ace411b872d9911abf4fc98"
            ]
          }
        },
        "ecaa63e35d1c44ce97df09049952b0dd": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": "row wrap",
            "width": "100%",
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": "inline-flex",
            "left": null
          }
        },
        "8ee716506d2a4a04a9ee5b4068eed047": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "state": {
            "_view_name": "ProgressView",
            "style": "IPY_MODEL_e5595ab0af494f4e84bb65b0bbc2dd46",
            "_dom_classes": [],
            "description": "Testing: 100%",
            "_model_name": "FloatProgressModel",
            "bar_style": "success",
            "max": 1,
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": 1,
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "orientation": "horizontal",
            "min": 0,
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_99bcd465410147d89a52d03d8f509043"
          }
        },
        "9773085f1ace411b872d9911abf4fc98": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "state": {
            "_view_name": "HTMLView",
            "style": "IPY_MODEL_581665da0e0e42b193e143076bd02a3c",
            "_dom_classes": [],
            "description": "",
            "_model_name": "HTMLModel",
            "placeholder": "​",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": " 5349/5349 [25:36&lt;00:00,  3.48it/s]",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_b33502a89e77483189998c79b0860412"
          }
        },
        "e5595ab0af494f4e84bb65b0bbc2dd46": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "ProgressStyleModel",
            "description_width": "initial",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "bar_color": null,
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "99bcd465410147d89a52d03d8f509043": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": "2",
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "581665da0e0e42b193e143076bd02a3c": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "DescriptionStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "b33502a89e77483189998c79b0860412": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        }
      }
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "bQrprNIah3g2"
      },
      "source": [
        "!pip install transformers==3.5.0\r\n",
        "!pip install pytorch-lightning\r\n",
        "!pip install ftfy\r\n",
        "!pip install neptune-client==0.4.130\r\n",
        "!pip install efficientnet-pytorch "
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "GYV4jQMnh4fC",
        "outputId": "7c6a0d77-5475-4177-bce5-b5df1b759634"
      },
      "source": [
        "import torch\r\n",
        "if torch.cuda.is_available(): \r\n",
        "   dev = \"cuda:0\"\r\n",
        "else: \r\n",
        "   dev = \"cpu\" \r\n",
        "print(dev, torch.cuda.get_device_name(0))\r\n",
        "device = torch.device(dev)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "cuda:0 Tesla V100-SXM2-16GB\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uu-p5WMMkP4H"
      },
      "source": [
        "import efficientnet_pytorch\r\n",
        "from efficientnet_pytorch import EfficientNet\r\n",
        "from torch import nn, optim\r\n",
        "from torch.utils.data import Dataset, DataLoader, TensorDataset\r\n",
        "import torch.nn.functional as F\r\n",
        "import torchvision\r\n",
        "from torchvision import transforms, utils\r\n",
        "from transformers import T5Tokenizer, T5ForConditionalGeneration, AutoTokenizer\r\n",
        "import neptune\r\n",
        "from pytorch_lightning.loggers import NeptuneLogger\r\n",
        "import pytorch_lightning as pl\r\n",
        "from pytorch_lightning.callbacks import ModelCheckpoint\r\n",
        "from pytorch_lightning.loggers import NeptuneLogger\r\n",
        "\r\n",
        "from random import randrange\r\n",
        "import random\r\n",
        "import numpy as np\r\n",
        "import collections\r\n",
        "import os\r\n",
        "import glob\r\n",
        "import json\r\n",
        "from ftfy import fix_encoding\r\n",
        "\r\n",
        "from PIL import Image\r\n",
        "from PIL import ImageDraw\r\n",
        "from PIL import ImageFont\r\n",
        "from PIL import ImageChops\r\n",
        "from matplotlib.pyplot import imshow\r\n",
        "import matplotlib.pyplot as plt\r\n",
        "import imageio\r\n",
        "from typing import Callable, Dict, List, Tuple"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hwlziTlylYz1"
      },
      "source": [
        "### Métricas"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "EKJYWZi8lJ74"
      },
      "source": [
        "def normalize_answer(s):\r\n",
        "    \"\"\"Lower text and remove extra whitespace.\"\"\"\r\n",
        "\r\n",
        "    def white_space_fix(text):\r\n",
        "        return ' '.join(text.split())\r\n",
        "\r\n",
        "    def lower(text):\r\n",
        "        return text.lower()\r\n",
        "\r\n",
        "    return white_space_fix(lower(s))\r\n",
        "\r\n",
        "def get_tokens(s):\r\n",
        "    if not s: return []\r\n",
        "    return normalize_answer(s).split()\r\n",
        "\r\n",
        "def compute_exact(a_gold, a_pred):\r\n",
        "    return int(normalize_answer(a_gold) == normalize_answer(a_pred))\r\n",
        "\r\n",
        "def compute_f1(a_gold, a_pred):\r\n",
        "    gold_toks = get_tokens(a_gold)\r\n",
        "    pred_toks = get_tokens(a_pred)\r\n",
        "    common = collections.Counter(gold_toks) & collections.Counter(pred_toks)\r\n",
        "    num_same = sum(common.values())\r\n",
        "    if len(gold_toks) == 0 or len(pred_toks) == 0:\r\n",
        "        # If either is no-answer, then F1 is 1 if they agree, 0 otherwise\r\n",
        "        return int(gold_toks == pred_toks)\r\n",
        "    if num_same == 0:\r\n",
        "        return 0\r\n",
        "    precision = 1.0 * num_same / len(pred_toks)\r\n",
        "    recall = 1.0 * num_same / len(gold_toks)\r\n",
        "    f1 = (2 * precision * recall) / (precision + recall)\r\n",
        "    return f1"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Ko-ol3z9luaO"
      },
      "source": [
        "### DocVQA"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "k4fUdlJulaHS",
        "outputId": "bca62c88-c4a4-493d-fdcf-1a071709e68e"
      },
      "source": [
        "from google.colab import drive\r\n",
        "drive.mount('/content/drive')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Mounted at /content/drive\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rTNsfCSRlwOT"
      },
      "source": [
        "import tarfile\r\n",
        "### unzip files\r\n",
        "for mode in ['train','val','test']:\r\n",
        "    tf = tarfile.open(\"/content/drive/MyDrive/OCR_checkpoints/{}.tar.gz\".format(mode))\r\n",
        "    tf.extractall()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "f14V1SLzmFKu"
      },
      "source": [
        "class DocVQA(Dataset): \r\n",
        "    '''\r\n",
        "    Adaptado a partir da classe dataset implementada pelo Diedre\r\n",
        "    '''\r\n",
        "\r\n",
        "    def __init__(self,\r\n",
        "                 mode: str,\r\n",
        "                 tokenizer_string: str = 't5-base', #'microsoft/layoutlm-base-uncased',\r\n",
        "                 transform: object = None,\r\n",
        "                 seq_len: int = 512,\r\n",
        "                 no_image: bool = False):\r\n",
        "        '''\r\n",
        "        mode: one of train, val and test.\r\n",
        "        tokenizer_string: input tokenizer string \r\n",
        "        transform: transforms to be applied to the document image if applicable.\r\n",
        "        seq_len: maximum sequence len of encoded tokens.\r\n",
        "        no_image: if True, don't load document images.\r\n",
        "        returns:\r\n",
        "            dict:\r\n",
        "                document: transformed document image.\r\n",
        "                input_tokens: tokenized text contained in the document.\r\n",
        "                input_text: text contained in the document.\r\n",
        "                bboxes: bounding boxes for each OCR detection in the document, on the format [tl_col, tl_row, br_col, br_row].\r\n",
        "        '''\r\n",
        "        super().__init__()\r\n",
        "        assert mode in [\"train\", \"val\", \"test\"]\r\n",
        "        with open(f\"{mode}/{mode}_v1.0.json\", 'r') as data_json_file:\r\n",
        "            self.data_json = json.load(data_json_file)\r\n",
        "\r\n",
        "        self.folder = f\"{mode}\"\r\n",
        "        self.tokenizer = AutoTokenizer.from_pretrained(tokenizer_string)\r\n",
        "        self.transform = transform\r\n",
        "        self.seq_len = seq_len\r\n",
        "        self.mode = mode\r\n",
        "        self.no_image = no_image\r\n",
        "\r\n",
        "        print(f\"{self.mode} DocVQA folder {self.folder} tokenizer {self.tokenizer} seq_len {self.seq_len} \"\r\n",
        "              f\"no_image {self.no_image}\")\r\n",
        "\r\n",
        "      \r\n",
        "\r\n",
        "    def __len__(self):\r\n",
        "        return len(self.data_json[\"data\"])\r\n",
        "\r\n",
        "    def __getitem__(self, i: int):\r\n",
        "        data = self.data_json[\"data\"][i]\r\n",
        "\r\n",
        "        if self.no_image:\r\n",
        "            document = \"NA\"\r\n",
        "        else:\r\n",
        "            document = np.array(Image.open(os.path.join(self.folder, data[\"image\"])).convert('RGB'))\r\n",
        "            \r\n",
        "        ID = data[\"ucsf_document_id\"] + '_' + data[\"ucsf_document_page_no\"]\r\n",
        "        ocr_file = os.path.join(self.folder, \"ocr_results\", ID + \".json\")\r\n",
        "        with open(ocr_file, 'r') as ocr_file:\r\n",
        "            ocr_info = json.load(ocr_file)\r\n",
        "\r\n",
        "      # Retira o texto da imagem a partir do OCR\r\n",
        "        lines = ocr_info['recognitionResults'][0]['lines']\r\n",
        "        nlines = len(lines)\r\n",
        "\r\n",
        "        bboxes = []\r\n",
        "        input_text = ''\r\n",
        "        for line in range(nlines):\r\n",
        "            input_text += lines[line]['text'] + ' '\r\n",
        "           \r\n",
        "\r\n",
        "        question = self.data_json[\"data\"][i]['question']\r\n",
        "        input_context = 'Question: ' + question + ' Context: ' + input_text #+ ' </s>'\r\n",
        "        input_tokens = self.tokenizer.encode_plus(input_context, padding='max_length', truncation=True, max_length=self.seq_len, return_tensors='pt',return_token_type_ids=True)\r\n",
        "      \r\n",
        "        target_text = random.choice(data[\"answers\"]) if self.mode == \"train\" else data.get(\"answers\", [\"NA\"])[0]\r\n",
        "        target = self.tokenizer.encode(target_text, padding='max_length', truncation=True, max_length=32, return_tensors='pt')[0]\r\n",
        "      \r\n",
        "        if self.transform is not None:\r\n",
        "            document = self.transform(document)\r\n",
        "\r\n",
        "        return_dict = {\"document\": document,\r\n",
        "                       \"input_ids\": input_tokens[\"input_ids\"].squeeze(),\r\n",
        "                       \"token_type_ids\": input_tokens[\"token_type_ids\"].squeeze(),\r\n",
        "                       \"attention_mask\": input_tokens[\"attention_mask\"].squeeze(),\r\n",
        "                       \"input_context\": input_context,\r\n",
        "                       \"target\": target,\r\n",
        "                       \"target_text\": target_text}\r\n",
        "\r\n",
        "        return return_dict"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "V4Rx7eJtqU6X"
      },
      "source": [
        "test_augmentations = transforms.Compose([\r\n",
        "     transforms.ToPILImage(),\r\n",
        "     transforms.Resize((740, 560)),\r\n",
        "     transforms.ToTensor(),\r\n",
        "     ])\r\n",
        "\r\n",
        "tokenizer_string = \"/content/drive/MyDrive/OCR_checkpoints/T5_NQ\"\r\n",
        "seq_len = 512"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NyhB0DTiQWpW"
      },
      "source": [
        "### Modelo"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BRnKYKQ3J3BK"
      },
      "source": [
        "class T5Finetuner(pl.LightningModule):\r\n",
        "\r\n",
        "\r\n",
        "    def __init__(self, train_dataloader, val_dataloader, test_dataloader, params):\r\n",
        "        super(T5Finetuner, self).__init__()\r\n",
        "\r\n",
        "        self.params = params\r\n",
        "        \r\n",
        "        self._train_dataloader = train_dataloader\r\n",
        "        self._val_dataloader   = val_dataloader\r\n",
        "        self._test_dataloader  = test_dataloader\r\n",
        "\r\n",
        "        self.encoder = EfficientNet.from_pretrained(model_name='efficientnet-b4', advprop= params['advprop'])\r\n",
        "        self.decoder = T5ForConditionalGeneration.from_pretrained(tokenizer_string)\r\n",
        "\r\n",
        "        self.cnn1 = nn.Conv2d(in_channels=160, out_channels=self.decoder.config.d_model, kernel_size=1) # b0 => in_channels = 112\r\n",
        "                                                                                                        # b4 => in_channels = 160\r\n",
        "        self.tokenizer = T5Tokenizer.from_pretrained(tokenizer_string)                                  # b7 => in_channels = 224\r\n",
        "        self.learning_rate = params['learning_rate']\r\n",
        "\r\n",
        "    def generate(self, embeddings):\r\n",
        "        ''' \r\n",
        "        Recebe as features do encoder e retorna dos decoded ids.\r\n",
        "        Adaptado da tarefa sobre decodificadores do semestre passado \r\n",
        "        '''\r\n",
        "        max_length = self.params['seq_len']\r\n",
        "\r\n",
        "        # Add start of sequence token\r\n",
        "        decoded_ids = torch.full((embeddings.shape[0], 1),\r\n",
        "                                 self.decoder.config.decoder_start_token_id,\r\n",
        "                                 dtype=torch.long).to(embeddings.device)\r\n",
        "\r\n",
        "        encoder_hidden_states = self.decoder.get_encoder()(inputs_embeds=embeddings)\r\n",
        "\r\n",
        "        for step in range(max_length-1): # testar max_length\r\n",
        "            logits = self.decoder(decoder_input_ids=decoded_ids, encoder_outputs=encoder_hidden_states)[0]\r\n",
        "            next_token_logits = logits[:, -1, :]\r\n",
        "\r\n",
        "            # Greedy decoding\r\n",
        "            next_token_id = next_token_logits.argmax(1).unsqueeze(-1)\r\n",
        "            \r\n",
        "            # Check if output is end of senquence for all batches\r\n",
        "            if torch.eq(next_token_id[:, -1], self.tokenizer.eos_token_id).all():\r\n",
        "                break\r\n",
        "\r\n",
        "            # Concatenate past ids with new id, keeping batch dimension\r\n",
        "            decoded_ids = torch.cat([decoded_ids, next_token_id], dim=-1)\r\n",
        "\r\n",
        "        return decoded_ids\r\n",
        "\r\n",
        "    def forward(self, batch): \r\n",
        "        \r\n",
        "        #image features\r\n",
        "        features = model.encoder.extract_endpoints(batch['document'])[\"reduction_4\"]  # Shape (N, 112, 16, 16)\r\n",
        "        features = self.cnn1(features)\r\n",
        "        embeddings = features.permute(0, 2, 3, 1).reshape(features.shape[0], -1, self.decoder.config.d_model)\r\n",
        "\r\n",
        "        # text features\r\n",
        "        question_embeds = self.decoder.encoder(input_ids=batch['input_ids'], attention_mask=batch['attention_mask'], return_dict=True).last_hidden_state\r\n",
        "\r\n",
        "        # concatenate image and question sentence embeddings\r\n",
        "        inputs_embeds = torch.cat((question_embeds, embeddings), dim=1)\r\n",
        "        target_ids = batch['target']\r\n",
        "\r\n",
        "        if self.training:\r\n",
        "            outputs = self.decoder(inputs_embeds=inputs_embeds, labels=target_ids, return_dict=True)\r\n",
        "            return outputs.loss\r\n",
        "        else:\r\n",
        "            return self.generate(inputs_embeds)\r\n",
        "\r\n",
        "    def training_step(self, batch, batch_idx): \r\n",
        "        loss = self(batch)\r\n",
        "        self.log('loss', loss, on_epoch=True, prog_bar=True)\r\n",
        "        return loss\r\n",
        "\r\n",
        "    def validation_step(self, batch, batch_idx):\r\n",
        "        pred_tokens = self(batch)\r\n",
        "        decoded_pred = [fix_encoding(self.tokenizer.decode(tokens)) for tokens in pred_tokens]\r\n",
        "        return {\"pred\": decoded_pred, \"target\": batch[\"target_text\"]}\r\n",
        "\r\n",
        "    def test_step(self, batch, batch_idx):\r\n",
        "        pred_tokens = self(batch)\r\n",
        "        decoded_pred = [fix_encoding(self.tokenizer.decode(tokens)) for tokens in pred_tokens]\r\n",
        "        return {\"pred\": decoded_pred, \"target\": batch[\"target_text\"]}\r\n",
        "\r\n",
        "    def validation_epoch_end(self, outputs):\r\n",
        "        # Flatten dos targets e preds para arrays\r\n",
        "        trues = sum([list(x['target']) for x in outputs], [])\r\n",
        "        preds = sum([list(x['pred']) for x in outputs], [])\r\n",
        "\r\n",
        "        n = randrange(len(trues))\r\n",
        "        print(f\"\\nSample Target: {trues[n]}\\nPrediction: {preds[n]}\\n\")\r\n",
        "\r\n",
        "        f1 = []\r\n",
        "        exact = []\r\n",
        "        for true, pred in zip(trues, preds):\r\n",
        "            f1.append(compute_f1(a_gold=true, a_pred=pred))\r\n",
        "            exact.append(compute_exact(a_gold=true, a_pred=pred))\r\n",
        "        f1 = np.mean(f1)\r\n",
        "        exact = np.mean(exact)\r\n",
        "\r\n",
        "        self.log(\"val_f1\", f1, prog_bar=True)\r\n",
        "        self.log(\"val_exact\", exact, prog_bar=True)\r\n",
        "\r\n",
        "    def test_epoch_end(self, outputs):\r\n",
        "        # Flatten dos targets e preds para arrays\r\n",
        "        trues = sum([list(x['target']) for x in outputs], [])\r\n",
        "        preds = sum([list(x['pred']) for x in outputs], [])  # TESTAR FIX ENCODING\r\n",
        "\r\n",
        "        for random in range(5):\r\n",
        "            n = randrange(len(trues))\r\n",
        "            print(f\"\\nSample Target: {trues[n]}\\nPrediction: {preds[n]}\\n\")\r\n",
        "\r\n",
        "        f1 = []\r\n",
        "        exact = []\r\n",
        "        for true, pred in zip(trues, preds):\r\n",
        "            f1.append(compute_f1(a_gold=true, a_pred=pred))\r\n",
        "            exact.append(compute_exact(a_gold=true, a_pred=pred))\r\n",
        "        f1 = np.mean(f1)\r\n",
        "        exact = np.mean(exact)\r\n",
        "\r\n",
        "        self.log(\"test_f1\", f1, prog_bar=True)\r\n",
        "        self.log(\"test_exact\", exact, prog_bar=True)\r\n",
        "\r\n",
        "    def configure_optimizers(self):\r\n",
        "        return torch.optim.Adam(\r\n",
        "            [p for p in self.parameters() if p.requires_grad],\r\n",
        "            lr=self.learning_rate, eps=1e-08)\r\n",
        "\r\n",
        "    def train_dataloader(self):\r\n",
        "        return self._train_dataloader\r\n",
        "\r\n",
        "    def val_dataloader(self):\r\n",
        "        return self._val_dataloader\r\n",
        "\r\n",
        "    def test_dataloader(self):\r\n",
        "        return self._test_dataloader\r\n",
        "\r\n",
        "    \r\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8RzpwT5oXFYJ"
      },
      "source": [
        "learning_rate =  5e-5#@param {type: \"number\"} 5e-5\r\n",
        "batch_size =    1#@param {type: \"integer\"} 32\r\n",
        "sequence =  32#@param {type: \"integer\"}\r\n",
        "patience =  5#@param {type: \"integer\"}\r\n",
        "max_epochs =  5#@param {type: \"integer\"}\r\n",
        "advprop = False#@param {type: \"boolean\"}\r\n",
        "\r\n",
        "params = {  \r\n",
        "    'advprop': advprop,  \r\n",
        "    'batch_size': batch_size,\r\n",
        "    'seq_len': sequence,\r\n",
        "    'learning_rate': learning_rate,\r\n",
        "    'max_epochs': max_epochs,\r\n",
        "    'patience': patience,\r\n",
        "    'monitor_variable': 'val_f1'\r\n",
        "}"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "RCXH8en8XNSP",
        "outputId": "b0a10c25-73da-4dcb-bf93-b62178b50d6d"
      },
      "source": [
        "data_augmentations = transforms.Compose([\r\n",
        "     transforms.ToPILImage(),\r\n",
        "     transforms.Resize((600, 400)), # 740, 560\r\n",
        "     transforms.ToTensor(),\r\n",
        "     ])\r\n",
        "\r\n",
        "train = DocVQA('train', tokenizer_string, data_augmentations, seq_len)\r\n",
        "val = DocVQA('val', tokenizer_string, data_augmentations, seq_len)\r\n",
        "test = DocVQA('val', tokenizer_string, data_augmentations, seq_len)\r\n",
        "\r\n",
        "train_loader = DataLoader(train,\r\n",
        "                          shuffle = True,\r\n",
        "                          batch_size=params['batch_size'],\r\n",
        "                          num_workers=4)\r\n",
        "\r\n",
        "val_loader = DataLoader(val,\r\n",
        "                        batch_size=params['batch_size'],\r\n",
        "                        num_workers=4)\r\n",
        "\r\n",
        "\r\n",
        "test_loader = DataLoader(test,\r\n",
        "                         batch_size=params['batch_size'],\r\n",
        "                         num_workers=4)\r\n",
        "\r\n",
        "print('Seq_len:', seq_len)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "train DocVQA folder train tokenizer PreTrainedTokenizer(name_or_path='/content/drive/MyDrive/OCR_checkpoints/T5_NQ', vocab_size=32100, model_max_len=512, is_fast=False, padding_side='right', special_tokens={'eos_token': '</s>', 'unk_token': '<unk>', 'pad_token': '<pad>', 'additional_special_tokens': ['<extra_id_0>', '<extra_id_1>', '<extra_id_2>', '<extra_id_3>', '<extra_id_4>', '<extra_id_5>', '<extra_id_6>', '<extra_id_7>', '<extra_id_8>', '<extra_id_9>', '<extra_id_10>', '<extra_id_11>', '<extra_id_12>', '<extra_id_13>', '<extra_id_14>', '<extra_id_15>', '<extra_id_16>', '<extra_id_17>', '<extra_id_18>', '<extra_id_19>', '<extra_id_20>', '<extra_id_21>', '<extra_id_22>', '<extra_id_23>', '<extra_id_24>', '<extra_id_25>', '<extra_id_26>', '<extra_id_27>', '<extra_id_28>', '<extra_id_29>', '<extra_id_30>', '<extra_id_31>', '<extra_id_32>', '<extra_id_33>', '<extra_id_34>', '<extra_id_35>', '<extra_id_36>', '<extra_id_37>', '<extra_id_38>', '<extra_id_39>', '<extra_id_40>', '<extra_id_41>', '<extra_id_42>', '<extra_id_43>', '<extra_id_44>', '<extra_id_45>', '<extra_id_46>', '<extra_id_47>', '<extra_id_48>', '<extra_id_49>', '<extra_id_50>', '<extra_id_51>', '<extra_id_52>', '<extra_id_53>', '<extra_id_54>', '<extra_id_55>', '<extra_id_56>', '<extra_id_57>', '<extra_id_58>', '<extra_id_59>', '<extra_id_60>', '<extra_id_61>', '<extra_id_62>', '<extra_id_63>', '<extra_id_64>', '<extra_id_65>', '<extra_id_66>', '<extra_id_67>', '<extra_id_68>', '<extra_id_69>', '<extra_id_70>', '<extra_id_71>', '<extra_id_72>', '<extra_id_73>', '<extra_id_74>', '<extra_id_75>', '<extra_id_76>', '<extra_id_77>', '<extra_id_78>', '<extra_id_79>', '<extra_id_80>', '<extra_id_81>', '<extra_id_82>', '<extra_id_83>', '<extra_id_84>', '<extra_id_85>', '<extra_id_86>', '<extra_id_87>', '<extra_id_88>', '<extra_id_89>', '<extra_id_90>', '<extra_id_91>', '<extra_id_92>', '<extra_id_93>', '<extra_id_94>', '<extra_id_95>', '<extra_id_96>', '<extra_id_97>', '<extra_id_98>', '<extra_id_99>']}) seq_len 512 no_image False\n",
            "val DocVQA folder val tokenizer PreTrainedTokenizer(name_or_path='/content/drive/MyDrive/OCR_checkpoints/T5_NQ', vocab_size=32100, model_max_len=512, is_fast=False, padding_side='right', special_tokens={'eos_token': '</s>', 'unk_token': '<unk>', 'pad_token': '<pad>', 'additional_special_tokens': ['<extra_id_0>', '<extra_id_1>', '<extra_id_2>', '<extra_id_3>', '<extra_id_4>', '<extra_id_5>', '<extra_id_6>', '<extra_id_7>', '<extra_id_8>', '<extra_id_9>', '<extra_id_10>', '<extra_id_11>', '<extra_id_12>', '<extra_id_13>', '<extra_id_14>', '<extra_id_15>', '<extra_id_16>', '<extra_id_17>', '<extra_id_18>', '<extra_id_19>', '<extra_id_20>', '<extra_id_21>', '<extra_id_22>', '<extra_id_23>', '<extra_id_24>', '<extra_id_25>', '<extra_id_26>', '<extra_id_27>', '<extra_id_28>', '<extra_id_29>', '<extra_id_30>', '<extra_id_31>', '<extra_id_32>', '<extra_id_33>', '<extra_id_34>', '<extra_id_35>', '<extra_id_36>', '<extra_id_37>', '<extra_id_38>', '<extra_id_39>', '<extra_id_40>', '<extra_id_41>', '<extra_id_42>', '<extra_id_43>', '<extra_id_44>', '<extra_id_45>', '<extra_id_46>', '<extra_id_47>', '<extra_id_48>', '<extra_id_49>', '<extra_id_50>', '<extra_id_51>', '<extra_id_52>', '<extra_id_53>', '<extra_id_54>', '<extra_id_55>', '<extra_id_56>', '<extra_id_57>', '<extra_id_58>', '<extra_id_59>', '<extra_id_60>', '<extra_id_61>', '<extra_id_62>', '<extra_id_63>', '<extra_id_64>', '<extra_id_65>', '<extra_id_66>', '<extra_id_67>', '<extra_id_68>', '<extra_id_69>', '<extra_id_70>', '<extra_id_71>', '<extra_id_72>', '<extra_id_73>', '<extra_id_74>', '<extra_id_75>', '<extra_id_76>', '<extra_id_77>', '<extra_id_78>', '<extra_id_79>', '<extra_id_80>', '<extra_id_81>', '<extra_id_82>', '<extra_id_83>', '<extra_id_84>', '<extra_id_85>', '<extra_id_86>', '<extra_id_87>', '<extra_id_88>', '<extra_id_89>', '<extra_id_90>', '<extra_id_91>', '<extra_id_92>', '<extra_id_93>', '<extra_id_94>', '<extra_id_95>', '<extra_id_96>', '<extra_id_97>', '<extra_id_98>', '<extra_id_99>']}) seq_len 512 no_image False\n",
            "val DocVQA folder val tokenizer PreTrainedTokenizer(name_or_path='/content/drive/MyDrive/OCR_checkpoints/T5_NQ', vocab_size=32100, model_max_len=512, is_fast=False, padding_side='right', special_tokens={'eos_token': '</s>', 'unk_token': '<unk>', 'pad_token': '<pad>', 'additional_special_tokens': ['<extra_id_0>', '<extra_id_1>', '<extra_id_2>', '<extra_id_3>', '<extra_id_4>', '<extra_id_5>', '<extra_id_6>', '<extra_id_7>', '<extra_id_8>', '<extra_id_9>', '<extra_id_10>', '<extra_id_11>', '<extra_id_12>', '<extra_id_13>', '<extra_id_14>', '<extra_id_15>', '<extra_id_16>', '<extra_id_17>', '<extra_id_18>', '<extra_id_19>', '<extra_id_20>', '<extra_id_21>', '<extra_id_22>', '<extra_id_23>', '<extra_id_24>', '<extra_id_25>', '<extra_id_26>', '<extra_id_27>', '<extra_id_28>', '<extra_id_29>', '<extra_id_30>', '<extra_id_31>', '<extra_id_32>', '<extra_id_33>', '<extra_id_34>', '<extra_id_35>', '<extra_id_36>', '<extra_id_37>', '<extra_id_38>', '<extra_id_39>', '<extra_id_40>', '<extra_id_41>', '<extra_id_42>', '<extra_id_43>', '<extra_id_44>', '<extra_id_45>', '<extra_id_46>', '<extra_id_47>', '<extra_id_48>', '<extra_id_49>', '<extra_id_50>', '<extra_id_51>', '<extra_id_52>', '<extra_id_53>', '<extra_id_54>', '<extra_id_55>', '<extra_id_56>', '<extra_id_57>', '<extra_id_58>', '<extra_id_59>', '<extra_id_60>', '<extra_id_61>', '<extra_id_62>', '<extra_id_63>', '<extra_id_64>', '<extra_id_65>', '<extra_id_66>', '<extra_id_67>', '<extra_id_68>', '<extra_id_69>', '<extra_id_70>', '<extra_id_71>', '<extra_id_72>', '<extra_id_73>', '<extra_id_74>', '<extra_id_75>', '<extra_id_76>', '<extra_id_77>', '<extra_id_78>', '<extra_id_79>', '<extra_id_80>', '<extra_id_81>', '<extra_id_82>', '<extra_id_83>', '<extra_id_84>', '<extra_id_85>', '<extra_id_86>', '<extra_id_87>', '<extra_id_88>', '<extra_id_89>', '<extra_id_90>', '<extra_id_91>', '<extra_id_92>', '<extra_id_93>', '<extra_id_94>', '<extra_id_95>', '<extra_id_96>', '<extra_id_97>', '<extra_id_98>', '<extra_id_99>']}) seq_len 512 no_image False\n",
            "Seq_len: 512\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7Tm0h374Ysf0"
      },
      "source": [
        "### Treinamento"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "tXtNdTv1Xv83",
        "outputId": "993d0fbd-6fc3-4407-978e-a2352ab4eda7"
      },
      "source": [
        "#### DocVQA\r\n",
        "#checkpoint_path = '/content/drive/MyDrive/OCR_checkpoints/DocVQA-EffT5-epoch=11-val_f1=0.58-val_exact=0.48.ckpt' # 2  \r\n",
        "checkpoint_path = '/content/drive/MyDrive/OCR_checkpoints/DocVQA-EffT5-epoch=13-val_f1=0.58-val_exact=0.48.ckpt' # 4  \r\n",
        "\r\n",
        "\r\n",
        "checkpoint_dir = os.path.dirname(os.path.abspath(checkpoint_path))\r\n",
        "print(f'Files in {checkpoint_dir}: {os.listdir(checkpoint_dir)}')\r\n",
        "print(f'Saving checkpoints to {checkpoint_dir}')\r\n",
        "\r\n",
        "\r\n",
        "checkpoint_callback = ModelCheckpoint(prefix=\"DocVQA-EffT5\",\r\n",
        "                                      filepath=\"/content/drive/MyDrive/OCR_checkpoints/{epoch}-{val_f1:.2f}-{val_exact:.2f}\",\r\n",
        "                                      save_top_k=-1)  # -1 = Keeps all checkpoints, 1 = save best\r\n",
        "\r\n",
        "resume_from_checkpoint = None\r\n",
        "if os.path.exists(checkpoint_path):\r\n",
        "    print(f'Restoring checkpoint: {checkpoint_path}')\r\n",
        "    resume_from_checkpoint = checkpoint_path\r\n",
        "\r\n",
        "callbacks = [pl.callbacks.EarlyStopping(monitor=params['monitor_variable'], \r\n",
        "                                        patience=params[\"patience\"], \r\n",
        "                                        mode='max')]\r\n",
        "\r\n",
        "# Log results to Neptune.\r\n",
        "neptune_logger = pl.loggers.neptune.NeptuneLogger(\r\n",
        "    api_key='eyJhcGlfYWRkcmVzcyI6Imh0dHBzOi8vdWkubmVwdHVuZS5haSIsImFwaV91cmwiOiJodHRwczovL3VpLm5lcHR1bmUuYWkiLCJhcGlfa2V5IjoiNmJkMmRkNGMtMzNlMi00MzY2LThiZTUtODMxYmFlMzUwYzcwIn0=',\r\n",
        "    project_name='guilhermemr04/sandbox',\r\n",
        "    params=params,)\r\n",
        "\r\n",
        "\r\n",
        "trainer = pl.Trainer(gpus=1,\r\n",
        "                     logger=neptune_logger,\r\n",
        "                     precision=32, \r\n",
        "                     log_gpu_memory=True,\r\n",
        "                     max_epochs=17,#params['max_epochs'],\r\n",
        "                     check_val_every_n_epoch=1,\r\n",
        "                     profiler=True,\r\n",
        "                     callbacks=None,#callbacks,\r\n",
        "                     accumulate_grad_batches=32,\r\n",
        "                     checkpoint_callback= checkpoint_callback,\r\n",
        "                     val_check_interval=0.25,  # check val when 25% is trained\r\n",
        "                     limit_val_batches=0.05,  # use 5% of dev set to evaluate\r\n",
        "                     progress_bar_refresh_rate=100,\r\n",
        "                     resume_from_checkpoint=resume_from_checkpoint)\r\n",
        "                     \r\n",
        "\r\n",
        "model = T5Finetuner(train_dataloader=train_loader,\r\n",
        "                    val_dataloader=val_loader,\r\n",
        "                    test_dataloader=test_loader,\r\n",
        "                    params=params)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Files in /content/drive/MyDrive/OCR_checkpoints: ['img2text-basic-epoch=0-val_exact=0.59.ckpt', 'img2text-basic-epoch=0-val_exact=0.70.ckpt', 'img2text-intermediate-epoch=8-val_exact=0.36.ckpt', 'img2text-final-epoch=47-val_exact=0.37.ckpt', 'img2text-final-epoch=74-val_exact=0.44.ckpt', 'img2text-Nota_Fiscal-epoch=88-val_exact=0.27.ckpt', 'img2text-Nota_Fiscal-epoch=95-val_exact=0.27.ckpt', 'img2text-teste-epoch=13-val_exact=0.33.ckpt', 'img2text-teste_2-epoch=19-val_exact=0.25.ckpt', 'img2text-teste_2-epoch=21-val_exact=0.28.ckpt', 'img2text-teste_2-epoch=22-val_exact=0.30.ckpt', 'img2text-teste_3-epoch=31-val_exact=0.10.ckpt', 'img2text-teste_3-epoch=32-val_exact=0.09.ckpt', 'img2text-SROIE-epoch=43-val_exact=0.22.ckpt', 'img2text-SROIE-epoch=51-val_exact=0.22.ckpt', 'img2text-SROIE_v2-epoch=40-val_exact=0.43.ckpt', 'img2text-SROIE_v2-epoch=47-val_exact=0.42.ckpt', 'img2text-SROIE_v3-epoch=41-val_exact=0.44.ckpt', 'img2text-SROIE_v3-epoch=46-val_exact=0.46.ckpt', 'test.tar.gz', 'val.tar.gz', 'train.tar.gz', 'img2text-SROIE_aula13-epoch=38-val_exact=0.17.ckpt', 'DocVQA-T5-epoch=3-val_f1=0.59-val_exact=0.50.ckpt', 'DocVQA-T5-epoch=4-val_f1=0.59-val_exact=0.50.ckpt', 'DocVQA-T5_NQ-epoch=3-val_f1=0.59-val_exact=0.50.ckpt', 'DocVQA-T5_NQ-epoch=4-val_f1=0.59-val_exact=0.50.ckpt', 'img2text-DocVQA_1-epoch=52-val_f1=0.25.ckpt', 'img2text-DocVQA_1-epoch=53-val_f1=0.23.ckpt', 'T5_NQ', 'DocVQA-EffT5-epoch=11-val_f1=0.58-val_exact=0.48.ckpt', 'DocVQA-EffT5-epoch=12-val_f1=0.60-val_exact=0.49.ckpt', 'DocVQA-EffT5-epoch=13-val_f1=0.58-val_exact=0.48.ckpt', 'DocVQA-EffT5-epoch=14-val_f1=0.58-val_exact=0.48.ckpt']\n",
            "Saving checkpoints to /content/drive/MyDrive/OCR_checkpoints\n",
            "Restoring checkpoint: /content/drive/MyDrive/OCR_checkpoints/DocVQA-EffT5-epoch=13-val_f1=0.58-val_exact=0.48.ckpt\n",
            "https://ui.neptune.ai/guilhermemr04/sandbox/e/SAN-38\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "NeptuneLogger will work in online mode\n",
            "GPU available: True, used: True\n",
            "TPU available: None, using: 0 TPU cores\n",
            "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Loaded pretrained weights for efficientnet-b4\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 645,
          "referenced_widgets": [
            "89f2469c883d4242a182854ce47f2ed8",
            "9ef92ef3c95144f99544bf7bb3ee3012",
            "9318e4693359435cbc1abb3d866f24db",
            "fc15df7b82c641699c8093dc5018ff23",
            "8f0f96ae44384b72a5a25491eebd964b",
            "bdcacd64868d42dab819d647920ffab4",
            "27c74922fe4741bfb149a2670e39c235",
            "860f7a264f5842cca7ef013306c1b871",
            "8cce9fa727dd40fba02af280b0b99c91",
            "1f565e0840c649c5b4503321ac3aafd5",
            "f9a5060a30ef40d08b1b097e361634a1",
            "5017f8ce3c724db79fc0d48738cf3362",
            "6a58e4f231e547a4aad7d03c3e48caa2",
            "c48a904f241c47bbae2d658625c404eb",
            "6deba002370242e49696ea4629ac2683",
            "c5bf72c2d4a84b8aa4e8ec199d3dd918"
          ]
        },
        "id": "vu8A7AiW0sGk",
        "outputId": "105fe209-e2e6-41d4-8aa8-f6f217fa5a8e"
      },
      "source": [
        "trainer.fit(model)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "\n",
            "  | Name    | Type                       | Params\n",
            "-------------------------------------------------------\n",
            "0 | encoder | EfficientNet               | 19.3 M\n",
            "1 | decoder | T5ForConditionalGeneration | 222 M \n",
            "2 | cnn1    | Conv2d                     | 123 K \n",
            "-------------------------------------------------------\n",
            "242 M     Trainable params\n",
            "0         Non-trainable params\n",
            "242 M     Total params\n",
            "Restored states from the checkpoint file at /content/drive/MyDrive/OCR_checkpoints/DocVQA-EffT5-epoch=13-val_f1=0.58-val_exact=0.48.ckpt\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "89f2469c883d4242a182854ce47f2ed8",
              "version_minor": 0,
              "version_major": 2
            },
            "text/plain": [
              "HBox(children=(FloatProgress(value=1.0, bar_style='info', description='Validation sanity check', layout=Layout…"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "\n",
            "Sample Target: university of california\n",
            "Prediction: university of california\n",
            "\n",
            "\r"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "8cce9fa727dd40fba02af280b0b99c91",
              "version_minor": 0,
              "version_major": 2
            },
            "text/plain": [
              "HBox(children=(FloatProgress(value=1.0, bar_style='info', description='Training', layout=Layout(flex='2'), max…"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/pytorch_lightning/utilities/distributed.py:49: UserWarning: Detected KeyboardInterrupt, attempting graceful shutdown...\n",
            "  warnings.warn(*args, **kwargs)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "error",
          "ename": "KeyboardInterrupt",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-21-45d4afebefac>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mtrainer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/pytorch_lightning/trainer/trainer.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, model, train_dataloader, val_dataloaders, datamodule)\u001b[0m\n\u001b[1;32m    470\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcall_hook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'on_fit_start'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    471\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 472\u001b[0;31m         \u001b[0mresults\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0maccelerator_backend\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    473\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0maccelerator_backend\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mteardown\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    474\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/pytorch_lightning/accelerators/gpu_accelerator.py\u001b[0m in \u001b[0;36mtrain\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m     66\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     67\u001b[0m         \u001b[0;31m# train or test\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 68\u001b[0;31m         \u001b[0mresults\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain_or_test\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     69\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mresults\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     70\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/pytorch_lightning/accelerators/accelerator.py\u001b[0m in \u001b[0;36mtrain_or_test\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m     67\u001b[0m             \u001b[0mresults\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrainer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrun_test\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     68\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 69\u001b[0;31m             \u001b[0mresults\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrainer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     70\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mresults\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     71\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/pytorch_lightning/trainer/trainer.py\u001b[0m in \u001b[0;36mtrain\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    552\u001b[0m         \u001b[0;32mfinally\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    553\u001b[0m             \u001b[0;31m# hook\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 554\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain_loop\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mon_train_end\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    555\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    556\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mrun_evaluation\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtest_mode\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mbool\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mFalse\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmax_batches\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/pytorch_lightning/trainer/training_loop.py\u001b[0m in \u001b[0;36mon_train_end\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    199\u001b[0m         \u001b[0;31m# when a checkpoint was saved at the last step\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    200\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrainer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mglobal_step\u001b[0m \u001b[0;34m-=\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 201\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcheck_checkpoint_callback\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mshould_save\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mis_last\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    202\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrainer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mglobal_step\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    203\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/pytorch_lightning/trainer/training_loop.py\u001b[0m in \u001b[0;36mcheck_checkpoint_callback\u001b[0;34m(self, should_save, is_last)\u001b[0m\n\u001b[1;32m    233\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    234\u001b[0m             \u001b[0;32mfor\u001b[0m \u001b[0mcallback\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mcheckpoint_callbacks\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 235\u001b[0;31m                 \u001b[0mcallback\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mon_validation_end\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrainer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    236\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    237\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mon_train_epoch_start\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mepoch\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/pytorch_lightning/callbacks/model_checkpoint.py\u001b[0m in \u001b[0;36mon_validation_end\u001b[0;34m(self, trainer, pl_module)\u001b[0m\n\u001b[1;32m    201\u001b[0m         \u001b[0mcheckpoints\u001b[0m \u001b[0mcan\u001b[0m \u001b[0mbe\u001b[0m \u001b[0msaved\u001b[0m \u001b[0mat\u001b[0m \u001b[0mthe\u001b[0m \u001b[0mend\u001b[0m \u001b[0mof\u001b[0m \u001b[0mthe\u001b[0m \u001b[0mval\u001b[0m \u001b[0mloop\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    202\u001b[0m         \"\"\"\n\u001b[0;32m--> 203\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msave_checkpoint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrainer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpl_module\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    204\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    205\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mon_save_checkpoint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrainer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpl_module\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0mDict\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mstr\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mAny\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/pytorch_lightning/callbacks/model_checkpoint.py\u001b[0m in \u001b[0;36msave_checkpoint\u001b[0;34m(self, trainer, pl_module)\u001b[0m\n\u001b[1;32m    251\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    252\u001b[0m         \u001b[0;31m# Mode 2: save the last checkpoint\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 253\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_save_last_checkpoint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrainer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpl_module\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmonitor_candidates\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    254\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    255\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__validate_init_configuration\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/pytorch_lightning/callbacks/model_checkpoint.py\u001b[0m in \u001b[0;36m_save_last_checkpoint\u001b[0;34m(self, trainer, pl_module, ckpt_name_metrics)\u001b[0m\n\u001b[1;32m    565\u001b[0m             \u001b[0maccelerator_backend\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mddp_plugin\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrpc_save_model\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_save_model\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlast_filepath\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrainer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpl_module\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    566\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 567\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_save_model\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlast_filepath\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrainer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpl_module\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    568\u001b[0m         if (\n\u001b[1;32m    569\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlast_model_path\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/pytorch_lightning/callbacks/model_checkpoint.py\u001b[0m in \u001b[0;36m_save_model\u001b[0;34m(self, filepath, trainer, pl_module)\u001b[0m\n\u001b[1;32m    359\u001b[0m         \u001b[0;31m# delegate the saving to the trainer\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    360\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msave_function\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 361\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msave_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfilepath\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msave_weights_only\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    362\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    363\u001b[0m             \u001b[0;32mraise\u001b[0m \u001b[0mValueError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\".save_function() not set\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/pytorch_lightning/trainer/properties.py\u001b[0m in \u001b[0;36msave_checkpoint\u001b[0;34m(self, filepath, weights_only)\u001b[0m\n\u001b[1;32m    254\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    255\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0msave_checkpoint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfilepath\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mweights_only\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mbool\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 256\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcheckpoint_connector\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msave_checkpoint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfilepath\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mweights_only\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    257\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    258\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mget_model\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/pytorch_lightning/trainer/connectors/checkpoint_connector.py\u001b[0m in \u001b[0;36msave_checkpoint\u001b[0;34m(self, filepath, weights_only)\u001b[0m\n\u001b[1;32m    397\u001b[0m                 \u001b[0mcheckpoint\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrainer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0maccelerator_backend\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mon_save\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcheckpoint\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    398\u001b[0m             \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 399\u001b[0;31m                 \u001b[0matomic_save\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcheckpoint\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfilepath\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    400\u001b[0m             \u001b[0;32mexcept\u001b[0m \u001b[0mAttributeError\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0merr\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    401\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0mLightningModule\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mCHECKPOINT_HYPER_PARAMS_KEY\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mcheckpoint\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/pytorch_lightning/utilities/cloud_io.py\u001b[0m in \u001b[0;36matomic_save\u001b[0;34m(checkpoint, filepath)\u001b[0m\n\u001b[1;32m     63\u001b[0m         \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msave\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcheckpoint\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbytesbuffer\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     64\u001b[0m     \u001b[0;32mwith\u001b[0m \u001b[0mfsspec\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfilepath\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"wb\"\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 65\u001b[0;31m         \u001b[0mf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwrite\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbytesbuffer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgetvalue\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 491,
          "referenced_widgets": [
            "d552ded803484eb882e57b75397aa54c",
            "515c4545b0fb44708e36ef7894a75bbc",
            "3cd0271d4f814fa5b0486a24dd0b220a",
            "19b0058cf73a421a898d1b5949e64ede",
            "abc87c7fc2114b30839c0aa894673085",
            "1c4eb617671445fc9a53ece103f01ef5",
            "21a472c1f31641ae9a5174433c33310f",
            "67378c2347fb4ab7a7aa9bde620be622"
          ]
        },
        "id": "wUqPAVa90sfE",
        "outputId": "1618831f-f30e-4d53-cfee-771d89b827ad"
      },
      "source": [
        "trainer.test(model) #2"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "d552ded803484eb882e57b75397aa54c",
              "version_minor": 0,
              "version_major": 2
            },
            "text/plain": [
              "HBox(children=(FloatProgress(value=1.0, bar_style='info', description='Testing', layout=Layout(flex='2'), max=…"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "\n",
            "Sample Target: $3,150.00\n",
            "Prediction: $3,150.00\n",
            "\n",
            "\n",
            "Sample Target: $1,384\n",
            "Prediction: $1.384.\n",
            "\n",
            "\n",
            "Sample Target: COPY\n",
            "Prediction: RJ REYNOLDS TOBACCO COMPANY\n",
            "\n",
            "\n",
            "Sample Target: indicate your approval, or criticism and return to us promptly\n",
            "Prediction: Minutes of yesterday's Committee Meeting\n",
            "\n",
            "\n",
            "Sample Target: Joe\n",
            "Prediction: Joe Copied/Aff\n",
            "\n",
            "\n",
            "--------------------------------------------------------------------------------\n",
            "DATALOADER:0 TEST RESULTS\n",
            "{'test_exact': 0.45971209571882593, 'test_f1': 0.5620391020905482}\n",
            "--------------------------------------------------------------------------------\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[{'test_exact': 0.45971209571882593, 'test_f1': 0.5620391020905482}]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 18
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IKvbcaVbIdiO",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 491,
          "referenced_widgets": [
            "81c98735a18d4b8588b3678f196077e4",
            "ecaa63e35d1c44ce97df09049952b0dd",
            "8ee716506d2a4a04a9ee5b4068eed047",
            "9773085f1ace411b872d9911abf4fc98",
            "e5595ab0af494f4e84bb65b0bbc2dd46",
            "99bcd465410147d89a52d03d8f509043",
            "581665da0e0e42b193e143076bd02a3c",
            "b33502a89e77483189998c79b0860412"
          ]
        },
        "outputId": "96c82ee0-4986-40d2-8d74-6e6cb53a96b7"
      },
      "source": [
        "trainer.test(model) # 4"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "81c98735a18d4b8588b3678f196077e4",
              "version_minor": 0,
              "version_major": 2
            },
            "text/plain": [
              "HBox(children=(FloatProgress(value=1.0, bar_style='info', description='Testing', layout=Layout(flex='2'), max=…"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "\n",
            "Sample Target: fao\n",
            "Prediction: food and agriculture organization\n",
            "\n",
            "\n",
            "Sample Target: Department of Obstetrics and Gynecology\n",
            "Prediction: Department of Obstetrics and Gynecology\n",
            "\n",
            "\n",
            "Sample Target: 1010\n",
            "Prediction: 1010\n",
            "\n",
            "\n",
            "Sample Target: Address\n",
            "Prediction: Address\n",
            "\n",
            "\n",
            "Sample Target: center support\n",
            "Prediction: Center Support\n",
            "\n",
            "\n",
            "--------------------------------------------------------------------------------\n",
            "DATALOADER:0 TEST RESULTS\n",
            "{'test_exact': 0.4733595064498037, 'test_f1': 0.5720039645077956}\n",
            "--------------------------------------------------------------------------------\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[{'test_exact': 0.4733595064498037, 'test_f1': 0.5720039645077956}]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 22
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QasOQt9zO6Tz"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}